{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["75HwYrwkDIb5"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# **Hyperparameter Search**"],"metadata":{"id":"44d89YrqseId"}},{"cell_type":"markdown","source":["# **Student Identification**"],"metadata":{"id":"-2wRS0QxWeuY"}},{"cell_type":"markdown","source":["Student Name       | Student Email\n","-------------------|------------------\n","Daniel Branco      | r20191230@novaims.unl.pt\n","Filipe Dias        | r20181050@novaims.unl.pt\n","Gonçalo Lourenço   | r20191097@novaims.unl.pt\n","Inês Santos        | r20191184@novaims.unl.pt\n","Manuel Marreiros   | r20191223@novaims.unl.pt"],"metadata":{"id":"m3SxcKjUCefA"}},{"cell_type":"markdown","source":["# **Data Source**\n","\n","Brain Tumor Classification (MRI) Dataset: https://www.kaggle.com/datasets/sartajbhuvaji/brain-tumor-classification-mri\n","\n","Drive with data: https://drive.google.com/file/d/1P3hcUss5Kqb28_WQUcTsuTW2VjNTX4pd/view?usp=share_link"],"metadata":{"id":"zDfu7s5EtOYW"}},{"cell_type":"markdown","source":["# **Notebook Summary**\n","\n","\n","\n"],"metadata":{"id":"-OR0ihcitTf7"}},{"cell_type":"markdown","source":["The selection of effective hyperparameters frequently has a significant impact on the performance of problems such as this. Using trial and error to determine appropriate values for these factors, which we have been doing so far, can only get so far and in that sense it is important to apply hyperparameter optimization algorithms to those models we consider to be the best to further enhance them. In our case, the model that show better performance in the handcraft notebook is our Convolutional Neural Network V6 (CNN_V6).\n","\n","The approach we decided to follow in order to find the ideal hyperparameter values was to use Keras Tuner. That way, we just had to define a search area of parameters (like the number of filters, kernel size, dropout rate, learning rate, etc) and then we were able to take advantage of the included methods of Keras Tuner. More specifically, we tried Bayesian Optimization, Hyperband, and Random Search."],"metadata":{"id":"_WbxnE0z4NEi"}},{"cell_type":"markdown","source":["# **References**\n","\n","1. [Guide to Hyperparameters Search For Deep Learning Models\n","](https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/)\n","2. [Random Search](https://keras.io/api/keras_tuner/tuners/random/#randomsearch-class)\n","3. [Bayesian Optimization](https://keras.io/api/keras_tuner/tuners/bayesian/#bayesianoptimization-class)\n","4. [Hyperband](https://keras.io/api/keras_tuner/tuners/hyperband/#hyperband-class)\n","5. [Hyperband: A Novel Bandit-Based Approach to\n","Hyperparameter Optimization](https://arxiv.org/pdf/1603.06560.pdf)\n","6. [A Gentle Introduction to Dropout for Regularizing Deep Neural Networks](https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/)"],"metadata":{"id":"MDkeW9SOUotp"}},{"cell_type":"markdown","source":["# **Imports**"],"metadata":{"id":"BrN6EI5vnQNX"}},{"cell_type":"code","source":["pip install keras-tuner tensorflow-addons --quiet"],"metadata":{"id":"SOWF-hCSU74z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680962384718,"user_tz":-60,"elapsed":5661,"user":{"displayName":"Filipe Marçal Dias","userId":"03521533956631762968"}},"outputId":"ca94f3b8-0996-48b9-9f98-788d13ef31b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.2/172.2 KB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 KB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import os\n","import time\n","import math\n","import random \n","import zipfile\n","import shutil\n","\n","import numpy as np\n","import pandas as pd\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","from matplotlib.colors import ListedColormap\n","\n","import tensorflow as tf\n","from tensorflow.keras import datasets\n","from tensorflow.keras.preprocessing import image_dataset_from_directory\n","from tensorflow.keras import Sequential, Model, layers, initializers, regularizers, optimizers, metrics \n","from tensorflow.keras.initializers import GlorotNormal\n","import tensorflow_addons as tfa\n","\n","import keras\n","from keras_tuner import Objective\n","import keras_tuner as kt\n","from kerastuner.tuners import RandomSearch, BayesianOptimization\n","from kerastuner.engine.hyperparameters import HyperParameters\n","from keras_tuner.tuners import Hyperband\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score"],"metadata":{"id":"TIJzOUDYDIb2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Things needed from previous notebooks**"],"metadata":{"id":"75HwYrwkDIb5"}},{"cell_type":"code","source":["#EXPLORATION\n","\n","# Set the machine\n","gdrive = True\n","# Set the connection string\n","path = \"/content/drive/MyDrive/Deep Learning/Projeto/\"\n","main_folder, training_folder, testing_folder = \"brain_tumor_data/\", \"Training/\", \"Testing/\"\n","# If using Google Drive\n","if gdrive:\n","    # Setup drive\n","    from google.colab import drive\n","    drive.mount('/content/drive')        \n","    # Transfer zip dataset to the current virtual machine\n","    t0 = time.time()\n","    shutil.copyfile(path + 'brain_tumor_data.zip', 'brain_tumor_data.zip')\n","    # Extract files\n","    zip_ = zipfile.ZipFile('brain_tumor_data.zip')\n","    zip_.extractall()\n","    zip_.close()\n","    print(\"File transfer completed in %0.3f seconds\" % (time.time() - t0))\n","    path = \"\"\n","\n","classes = [\"no_tumor\", \"glioma_tumor\", \"meningioma_tumor\", \"pituitary_tumor\"]\n","\n","# Create empty lists to store the number of instances and class names\n","n_train = []\n","class_names = []\n","\n","# Loop through each class in the dataset\n","for c in classes:\n","    # Get the number of instances in the training set for the current class\n","    n_train_c = len(os.listdir(path + main_folder + training_folder + f\"/{c}\"))\n","    # Append the number of instances and class name to their respective lists\n","    n_train.append(n_train_c)\n","    class_names.append(c)\n","\n","image_size=(128, 128)\n","crop_to_aspect_ratio=True\n","color_mode='grayscale'\n","batch_size=64\n","label_mode=\"categorical\"\n","validation_split=0.2\n","shuffle=True\n","seed=0\n","\n","ds_train, ds_val = image_dataset_from_directory(path + main_folder + training_folder, \n","                                                image_size=image_size,\n","                                                crop_to_aspect_ratio=crop_to_aspect_ratio,\n","                                                color_mode=color_mode,\n","                                                batch_size=batch_size,\n","                                                label_mode=label_mode,\n","                                                subset='both',\n","                                                validation_split=validation_split, \n","                                                shuffle=shuffle,\n","                                                seed=seed)\n","\n","iter_train = iter(ds_train)\n","batch_x_train, batch_y_train = iter_train.next()\n","\n","n_classes = len(classes)\n","total_samples = np.sum(n_train)\n","\n","#PREPROCESSING\n","\n","class_weights = {}\n","for i in range(n_classes):\n","    w = total_samples / (2.0 * n_train[i])\n","    class_weights[i] = w\n","\n","print('Class counts:', n_train)\n","print('Class weights:', class_weights)\n","\n","input_shape = tuple(batch_x_train.shape)\n","rescaling = layers.Rescaling(1./255)\n","batchnormalization = layers.BatchNormalization()\n","\n","rotation_layer = layers.RandomRotation(factor=0.05)\n","zoom_layer = layers.RandomZoom(height_factor=0.05, width_factor=0.05)\n","contrast_layer = layers.RandomContrast(factor=0.10)\n","brightness_layer = layers.RandomBrightness(factor=0.05)\n","noise_layer = layers.GaussianNoise(0.05)\n","flip_layer = layers.RandomFlip(mode='horizontal')\n","crop_layer = layers.RandomCrop(height=300, width=300)\n","translation_layer = layers.RandomTranslation(height_factor=0.1, width_factor=0.1)\n","\n","def augmentation(inputs):\n","    x = rotation_layer(inputs)\n","    x = zoom_layer(x)\n","    x = contrast_layer(x)\n","    x = brightness_layer(x)\n","    x = noise_layer(x)\n","    return x\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b10194f4-bb9e-41b5-f548-07a89c0df8d0","executionInfo":{"status":"ok","timestamp":1680975213678,"user_tz":-60,"elapsed":7672,"user":{"displayName":"InfoSS","userId":"03001223037444999152"}},"id":"YaMhLCiqDIb6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","File transfer completed in 2.394 seconds\n","Found 2870 files belonging to 4 classes.\n","Using 2296 files for training.\n","Using 574 files for validation.\n","Class counts: [395, 826, 822, 827]\n","Class weights: {0: 3.632911392405063, 1: 1.7372881355932204, 2: 1.745742092457421, 3: 1.735187424425635}\n"]}]},{"cell_type":"markdown","source":["# **Hyperparameter search**\n","First, below is a simple function to print the best parameters in each model."],"metadata":{"id":"ZnDDOuKjDIb8"}},{"cell_type":"code","source":["def print_hyperparameters_table(best_hyperparameters):\n","    # define a dictionary to map hyperparameter names to their values\n","    hyperparams_dict = {}\n","    # Check and add hyperparameters to the dictionary if they exist in the best_hyperparameters dictionary\n","    if 'filters_1' in best_hyperparameters:\n","        hyperparams_dict[\"filters_1\"] = best_hyperparameters.get('filters_1')\n","    if 'filters_2' in best_hyperparameters:\n","        hyperparams_dict[\"filters_2\"] = best_hyperparameters.get('filters_2')\n","    if 'dropout_rate' in best_hyperparameters:\n","        hyperparams_dict[\"dropout_rate\"] = best_hyperparameters.get('dropout_rate')\n","    if 'kernel_height_width' in best_hyperparameters:\n","        hyperparams_dict[\"kernel_height_width\"] = best_hyperparameters.get('kernel_height_width')\n","    if 'learning_rate' in best_hyperparameters:\n","        hyperparams_dict[\"learning_rate\"] = best_hyperparameters.get('learning_rate')\n","    if 'n_conv2d' in best_hyperparameters:\n","        hyperparams_dict[\"n_conv2d\"] = best_hyperparameters.get('n_conv2d')\n","\n","    # define the header row of the table\n","    header = \"| Hyperparameter | Value |\"\n","    # print the header and separator rows\n","    print(header)\n","\n","    # loop through the hyperparameters dictionary and print each one in a row of the table\n","    for param, value in hyperparams_dict.items():\n","        row = f\"| {param} | {value} |\"\n","        print(row)\n"],"metadata":{"id":"lMwpAb0cDIb9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Random Search**"],"metadata":{"id":"kalE-o6mDIb-"}},{"cell_type":"markdown","source":["###CNN_V6_HYPER_1\n","The first hyperparameter search method used for this project is the random search due to the low computational power needed for it. Our group decided to give more trials to this model as it is a technique based on randomness, thus the greater number of trials, the higher the chance of getting good parameters as a starting point.\n","\n","Our code will perform a random search over the hyperparameter space defined in the build_model function, with the goal of finding the set of hyperparameters that maximize the \"val_F1-Score\" on the validation data. We chose \"val_F1-Score\" because it is a more robust metric than the accuracy.\n","\n","The search will be performed for a maximum of 10 trials, with each trial corresponding to a different set of hyperparameters. If a trial fails due to an error, it will be retried at most 3 times.[2]\n"],"metadata":{"id":"2GZHW8IGDIb_"}},{"cell_type":"code","source":["class CNN_V6_HYPER_1(tf.keras.Model):\n","    def __init__(self, seed=0, filters_1=32, filters_2=64, dropout_rate=0.25 , kernel_height_width=3):\n","        super().__init__()\n","        self.augmentation = augmentation\n","        self.batchnormalization = layers.BatchNormalization()\n","        self.conv1 = layers.Conv2D(\n","            filters=32*input_shape[-1], \n","            kernel_size=(3, 3), \n","            kernel_initializer=initializers.GlorotNormal(seed=seed),\n","            kernel_regularizer=regularizers.l2(0.001),\n","        )\n","        self.relu = layers.Activation(\"relu\")\n","        self.maxpool = layers.MaxPooling2D(pool_size=(2, 2))          \n","        self.conv2 = layers.Conv2D(\n","            filters=64*input_shape[-1], \n","            kernel_size=(3, 3), \n","            kernel_initializer=initializers.GlorotNormal(seed=seed),\n","            kernel_regularizer=regularizers.l2(0.001), \n","        )\n","        self.dropout = layers.Dropout(0.3) \n","        self.flatten = layers.Flatten()\n","        self.dense1 = layers.Dense(\n","            units=4, \n","            activation=\"softmax\", \n","            kernel_initializer=initializers.GlorotNormal(seed=seed),\n","            kernel_regularizer=regularizers.l2(0.001), \n","            activity_regularizer=regularizers.l1(0.001) \n","        ) \n","\n","    def call(self, inputs):\n","        x = self.augmentation(inputs)\n","        x = self.batchnormalization(x)\n","        x = self.conv1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","        x = self.conv2(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","        x = self.dropout(x)\n","        x = self.flatten(x)\n","        x = self.dense1(x)\n","        return x\n","\n","def build_model(hp):\n","    cnn_v6_hyper_1 = CNN_V6_HYPER_1(\n","        seed=seed,\n","        filters_1=hp.Int('filters_1', min_value=6, max_value=128, step=16),\n","        filters_2=hp.Int('filters_2', min_value=6, max_value=128, step=16),\n","        dropout_rate=hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1),\n","        kernel_height_width=hp.Int('kernel_height_width', min_value=3, max_value=11, step=2)\n","    )\n","    cnn_v6_hyper_1.build(input_shape)\n","    cnn_v6_hyper_1.compile(\n","        optimizer=keras.optimizers.RMSprop(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n","        loss=\"categorical_crossentropy\",\n","        metrics=[metrics.CategoricalAccuracy(name='accuracy'),\n","        tfa.metrics.F1Score(num_classes=4, average='macro', name='F1-Score')])\n","\n","    return cnn_v6_hyper_1\n","# Use Keras Tuner library to search for the best hyperparameters\n","tuner_cnn_v6_hyper_1 = RandomSearch(\n","    build_model,\n","    objective=Objective('val_F1-Score', direction='max'),\n","    max_trials=10,\n","    overwrite=True,\n","    max_retries_per_trial=3\n","    )\n","\n","tuner_cnn_v6_hyper_1.search(ds_train, epochs=5, validation_data=ds_val,class_weight = class_weights)\n","\n","# Train the model with the best hyperparameters\n","best_model_cnn_v6_hyper_1 = tuner_cnn_v6_hyper_1.get_best_models(num_models=1)[0]\n","best_hyperparameters_cnn_v6_hyper_1 = tuner_cnn_v6_hyper_1.get_best_hyperparameters(num_trials=1)[0]\n","\n","best_model_cnn_v6_hyper_1.fit(ds_train, epochs=10, validation_data=ds_val,class_weight = class_weights)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"86118c7a-4c33-4593-91cd-c271f9874bd7","id":"EQiXNB4PDIb_"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 10 Complete [00h 00m 26s]\n","val_F1-Score: 0.807634711265564\n","\n","Best val_F1-Score So Far: 0.807634711265564\n","Total elapsed time: 00h 03m 44s\n","Epoch 1/10\n","36/36 [==============================] - 4s 72ms/step - loss: 1.1924 - accuracy: 0.7922 - F1-Score: 0.7845 - val_loss: 0.5894 - val_accuracy: 0.7962 - val_F1-Score: 0.7937\n","Epoch 2/10\n","36/36 [==============================] - 3s 66ms/step - loss: 1.1326 - accuracy: 0.8031 - F1-Score: 0.7985 - val_loss: 0.5386 - val_accuracy: 0.8293 - val_F1-Score: 0.8246\n","Epoch 3/10\n","36/36 [==============================] - 3s 66ms/step - loss: 1.0887 - accuracy: 0.8149 - F1-Score: 0.8118 - val_loss: 0.7422 - val_accuracy: 0.7300 - val_F1-Score: 0.7138\n","Epoch 4/10\n","36/36 [==============================] - 3s 67ms/step - loss: 1.0240 - accuracy: 0.8297 - F1-Score: 0.8280 - val_loss: 0.5819 - val_accuracy: 0.8240 - val_F1-Score: 0.8204\n","Epoch 5/10\n","36/36 [==============================] - 3s 78ms/step - loss: 0.9480 - accuracy: 0.8423 - F1-Score: 0.8405 - val_loss: 0.8236 - val_accuracy: 0.7230 - val_F1-Score: 0.7127\n","Epoch 6/10\n","36/36 [==============================] - 3s 67ms/step - loss: 0.9118 - accuracy: 0.8584 - F1-Score: 0.8610 - val_loss: 0.5755 - val_accuracy: 0.8380 - val_F1-Score: 0.8348\n","Epoch 7/10\n","36/36 [==============================] - 3s 67ms/step - loss: 0.8506 - accuracy: 0.8702 - F1-Score: 0.8698 - val_loss: 0.5813 - val_accuracy: 0.8345 - val_F1-Score: 0.8291\n","Epoch 8/10\n","36/36 [==============================] - 4s 93ms/step - loss: 0.8007 - accuracy: 0.8785 - F1-Score: 0.8766 - val_loss: 0.7099 - val_accuracy: 0.8049 - val_F1-Score: 0.7987\n","Epoch 9/10\n","36/36 [==============================] - 3s 66ms/step - loss: 0.7829 - accuracy: 0.8794 - F1-Score: 0.8797 - val_loss: 0.6496 - val_accuracy: 0.8310 - val_F1-Score: 0.8240\n","Epoch 10/10\n","36/36 [==============================] - 3s 67ms/step - loss: 0.7272 - accuracy: 0.8924 - F1-Score: 0.8918 - val_loss: 0.4710 - val_accuracy: 0.8920 - val_F1-Score: 0.8871\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fc2fc61e190>"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["print_hyperparameters_table(best_hyperparameters_cnn_v6_hyper_1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f55453d6-0373-4f86-cb97-af5f6f04eb0a","id":"yrs3A_gpDIcC"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["| Hyperparameter | Value |\n","| filters_1 | 86 |\n","| filters_2 | 54 |\n","| dropout_rate | 0.2 |\n","| kernel_height_width | 3 |\n","| learning_rate | 0.001 |\n"]}]},{"cell_type":"code","source":["best_model_cnn_v6_hyper_1.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ce3a929e-8cf3-40e6-936d-0f870bbcab70","id":"JhiH6qGGDIcD"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"cnn_v6_hyper_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," batch_normalization (BatchN  multiple                 4         \n"," ormalization)                                                   \n","                                                                 \n"," conv2d (Conv2D)             multiple                  320       \n","                                                                 \n"," activation (Activation)     multiple                  0         \n","                                                                 \n"," max_pooling2d (MaxPooling2D  multiple                 0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           multiple                  18496     \n","                                                                 \n"," dropout (Dropout)           multiple                  0         \n","                                                                 \n"," flatten (Flatten)           multiple                  0         \n","                                                                 \n"," dense (Dense)               multiple                  230404    \n","                                                                 \n","=================================================================\n","Total params: 249,224\n","Trainable params: 249,222\n","Non-trainable params: 2\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["## **Bayesian Optimization**\n","At this point, we understood that computational power was not an issue and we started to explore hyperparameters methods more computationally demanding in search for better performance. Also, as the name says, random search is a technique that gives random results which aren't guaranteed to be the best ones. \n","\n","Below, we decided to explore the Bayesian Optimization technique keeping all the previous model configurations."],"metadata":{"id":"qM7Nabr1DIcE"}},{"cell_type":"markdown","source":["###CNN_V6_HYPER_2"],"metadata":{"id":"giGzxeu8DIcF"}},{"cell_type":"code","source":["# Use Keras Tuner library to search for the best hyperparameters\n","tuner_cnn_v6_hyper_2 = BayesianOptimization(\n","    build_model,\n","    objective=Objective('val_F1-Score', direction='max'),\n","    max_trials=5,\n","    overwrite=True,\n","    max_retries_per_trial=3\n","    )\n","\n","tuner_cnn_v6_hyper_2.search(ds_train, epochs=5, validation_data=ds_val,class_weight = class_weights)\n","\n","# Train the model with the best hyperparameters\n","best_model_cnn_v6_hyper_2 = tuner_cnn_v6_hyper_2.get_best_models(num_models=1)[0]\n","best_hyperparameters_cnn_v6_hyper_2 = tuner_cnn_v6_hyper_2.get_best_hyperparameters(num_trials=1)[0]\n","\n","best_model_cnn_v6_hyper_2.fit(ds_train, epochs=10, validation_data=ds_val,class_weight = class_weights)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"252cab51-55e9-4f60-f800-aec1fa706b90","id":"8R_cejXEDIcG"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 5 Complete [00h 00m 20s]\n","val_F1-Score: 0.8100018501281738\n","\n","Best val_F1-Score So Far: 0.8100018501281738\n","Total elapsed time: 00h 01m 40s\n","Epoch 1/10\n","36/36 [==============================] - 4s 72ms/step - loss: 1.1958 - accuracy: 0.7901 - F1-Score: 0.7840 - val_loss: 0.6147 - val_accuracy: 0.8014 - val_F1-Score: 0.7927\n","Epoch 2/10\n","36/36 [==============================] - 3s 67ms/step - loss: 1.1930 - accuracy: 0.7844 - F1-Score: 0.7810 - val_loss: 0.7769 - val_accuracy: 0.7422 - val_F1-Score: 0.7248\n","Epoch 3/10\n","36/36 [==============================] - 4s 103ms/step - loss: 1.0649 - accuracy: 0.8184 - F1-Score: 0.8128 - val_loss: 0.5112 - val_accuracy: 0.8467 - val_F1-Score: 0.8447\n","Epoch 4/10\n","36/36 [==============================] - 3s 68ms/step - loss: 1.0083 - accuracy: 0.8341 - F1-Score: 0.8330 - val_loss: 0.5970 - val_accuracy: 0.8066 - val_F1-Score: 0.8051\n","Epoch 5/10\n","36/36 [==============================] - 3s 67ms/step - loss: 0.9304 - accuracy: 0.8502 - F1-Score: 0.8480 - val_loss: 0.5360 - val_accuracy: 0.8537 - val_F1-Score: 0.8483\n","Epoch 6/10\n","36/36 [==============================] - 3s 67ms/step - loss: 0.9039 - accuracy: 0.8537 - F1-Score: 0.8496 - val_loss: 0.7216 - val_accuracy: 0.7544 - val_F1-Score: 0.7445\n","Epoch 7/10\n","36/36 [==============================] - 4s 111ms/step - loss: 0.8354 - accuracy: 0.8676 - F1-Score: 0.8662 - val_loss: 0.7107 - val_accuracy: 0.8066 - val_F1-Score: 0.8051\n","Epoch 8/10\n","36/36 [==============================] - 3s 73ms/step - loss: 0.8162 - accuracy: 0.8702 - F1-Score: 0.8691 - val_loss: 0.4843 - val_accuracy: 0.8850 - val_F1-Score: 0.8851\n","Epoch 9/10\n","36/36 [==============================] - 3s 66ms/step - loss: 0.7572 - accuracy: 0.8898 - F1-Score: 0.8897 - val_loss: 0.5016 - val_accuracy: 0.8659 - val_F1-Score: 0.8644\n","Epoch 10/10\n","36/36 [==============================] - 4s 100ms/step - loss: 0.7381 - accuracy: 0.8959 - F1-Score: 0.8979 - val_loss: 0.7264 - val_accuracy: 0.7875 - val_F1-Score: 0.7872\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fc2fcbe5c40>"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["print_hyperparameters_table(best_hyperparameters_cnn_v6_hyper_2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6cf4740d-a0ae-4ca1-b65a-9a566bff390a","id":"rXSzEF7NDIcI"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["| Hyperparameter | Value |\n","| filters_1 | 102 |\n","| filters_2 | 54 |\n","| dropout_rate | 0.30000000000000004 |\n","| kernel_height_width | 11 |\n","| learning_rate | 0.001 |\n"]}]},{"cell_type":"markdown","source":["###CNN_V6_HYPER_3\n"],"metadata":{"id":"MmIvja7dDIcJ"}},{"cell_type":"markdown","source":["With the results from the first approaches using Random Search and Bayesian Optimization our group gathered some important inputs regarding the hyperparameters. We found out that the dropout_rate is always close to 0.3, the  kernel_height_width around 3, the learning_rate near 0.001 and that the diference between the number of filters is normally small but they assume high values.\n","\n","\n","Furthermore, with the goal to explore a little more we thought about changes in the structure of our model by adding a loop inside the class to create blocks of  Conv2D layers, Activation layers and Maxpolling2D layers. The choice of the numbers of loops generated is processsed as a hyperparameter named 'n_conv2d' with a range from 2 to 4 blocks of layers.\n"],"metadata":{"id":"eIiRMw2cDIcL"}},{"cell_type":"code","source":["class CNN_V6_HYPER_3(tf.keras.Model):\n","    def __init__(self, seed=0, filters_1=64, dropout_rate=0.3, kernel_height_width=2, n_conv2d=2):\n","        super().__init__()\n","        self.augmentation = augmentation\n","        self.batchnormalization = layers.BatchNormalization()\n","        self.conv_layers = []\n","        for i in range(n_conv2d):\n","            self.conv_layers.append(layers.Conv2D(filters=filters_1*input_shape[-1], \n","                                                  kernel_size=(kernel_height_width,kernel_height_width), \n","                                                  kernel_initializer=initializers.GlorotNormal(seed=seed),\n","                                                  kernel_regularizer=regularizers.l2(0.001)))\n","            self.conv_layers.append(layers.Activation(\"relu\"))\n","            self.conv_layers.append(layers.MaxPooling2D(pool_size=(2, 2)))\n","        self.dropout = layers.Dropout(dropout_rate) \n","        self.flatten = layers.Flatten()\n","        self.dense1 = layers.Dense(units=4, \n","                                   activation=\"softmax\", \n","                                   kernel_initializer=initializers.GlorotNormal(seed=seed),\n","                                   kernel_regularizer=regularizers.l2(0.001), \n","                                   activity_regularizer=regularizers.l1(0.001) \n","                                   ) \n","\n","    def call(self, inputs):\n","        x = self.augmentation(inputs)\n","        x = self.batchnormalization(x)\n","        for layer in self.conv_layers:\n","            x = layer(x)\n","        x = self.dropout(x)\n","        x = self.flatten(x)\n","        x = self.dense1(x)\n","        return x\n","\n","def build_model(hp):\n","    cnn_v6_hyper_3 = CNN_V6_HYPER_3(\n","        seed=seed,\n","        filters_1=hp.Int('filters_1', min_value=64, max_value=128, step=8),\n","        dropout_rate=hp.Float('dropout_rate', min_value=0.3, max_value=0.5, step=0.05),\n","        kernel_height_width=hp.Int('kernel_height_width', min_value=2, max_value=6, step=1),\n","        n_conv2d=hp.Int('n_conv2d', min_value=2, max_value=4, step=1)\n","    )\n","    cnn_v6_hyper_3.build(input_shape)\n","    cnn_v6_hyper_3.compile(\n","        optimizer=keras.optimizers.RMSprop(hp.Choice('learning_rate', values=[ 0.0005,0.001,0.005])),\n","        loss=\"categorical_crossentropy\",\n","        metrics=[metrics.CategoricalAccuracy(name='accuracy'),\n","        tfa.metrics.F1Score(num_classes=4, average='macro', name='F1-Score')])\n","\n","    return cnn_v6_hyper_3\n","# Use Keras Tuner library to search for the best hyperparameters\n","tuner_cnn_v6_hyper_3 = BayesianOptimization(\n","    build_model,\n","    objective=Objective('val_F1-Score', direction='max'),\n","    max_trials=5,\n","    overwrite=True,\n","    max_retries_per_trial=3\n","    )\n","\n","tuner_cnn_v6_hyper_3.search(ds_train, epochs=5, validation_data=ds_val,class_weight = class_weights)\n","\n","# Train the model with the best hyperparameters\n","best_model_cnn_v6_hyper_3 = tuner_cnn_v6_hyper_3.get_best_models(num_models=1)[0]\n","best_hyperparameters_cnn_v6_hyper_3 = tuner_cnn_v6_hyper_3.get_best_hyperparameters(num_trials=1)[0]\n","\n","best_model_cnn_v6_hyper_3.fit(ds_train, epochs=10, validation_data=ds_val,class_weight = class_weights)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2631ed69-dcc4-4d22-bccd-558a9b7afef6","id":"S1D9zVljDIcM"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 5 Complete [00h 00m 22s]\n","val_F1-Score: 0.7964640855789185\n","\n","Best val_F1-Score So Far: 0.7964640855789185\n","Total elapsed time: 00h 02m 45s\n","Epoch 1/10\n","36/36 [==============================] - 6s 115ms/step - loss: 1.2378 - accuracy: 0.7783 - F1-Score: 0.7679 - val_loss: 0.7136 - val_accuracy: 0.7456 - val_F1-Score: 0.7307\n","Epoch 2/10\n","36/36 [==============================] - 3s 80ms/step - loss: 1.1892 - accuracy: 0.7805 - F1-Score: 0.7752 - val_loss: 0.5787 - val_accuracy: 0.8275 - val_F1-Score: 0.8247\n","Epoch 3/10\n","36/36 [==============================] - 3s 78ms/step - loss: 1.0838 - accuracy: 0.8206 - F1-Score: 0.8193 - val_loss: 0.5316 - val_accuracy: 0.8415 - val_F1-Score: 0.8377\n","Epoch 4/10\n","36/36 [==============================] - 4s 106ms/step - loss: 1.0132 - accuracy: 0.8328 - F1-Score: 0.8255 - val_loss: 0.8313 - val_accuracy: 0.7387 - val_F1-Score: 0.7211\n","Epoch 5/10\n","36/36 [==============================] - 4s 90ms/step - loss: 0.9483 - accuracy: 0.8410 - F1-Score: 0.8403 - val_loss: 0.5343 - val_accuracy: 0.8484 - val_F1-Score: 0.8441\n","Epoch 6/10\n","36/36 [==============================] - 3s 78ms/step - loss: 0.9576 - accuracy: 0.8489 - F1-Score: 0.8456 - val_loss: 0.8217 - val_accuracy: 0.7474 - val_F1-Score: 0.7311\n","Epoch 7/10\n","36/36 [==============================] - 4s 90ms/step - loss: 0.8889 - accuracy: 0.8524 - F1-Score: 0.8501 - val_loss: 0.5288 - val_accuracy: 0.8397 - val_F1-Score: 0.8394\n","Epoch 8/10\n","36/36 [==============================] - 4s 96ms/step - loss: 0.8526 - accuracy: 0.8724 - F1-Score: 0.8702 - val_loss: 0.6945 - val_accuracy: 0.7892 - val_F1-Score: 0.7837\n","Epoch 9/10\n","36/36 [==============================] - 3s 78ms/step - loss: 0.7856 - accuracy: 0.8868 - F1-Score: 0.8863 - val_loss: 0.5311 - val_accuracy: 0.8676 - val_F1-Score: 0.8636\n","Epoch 10/10\n","36/36 [==============================] - 4s 106ms/step - loss: 0.7609 - accuracy: 0.8889 - F1-Score: 0.8885 - val_loss: 0.5283 - val_accuracy: 0.8641 - val_F1-Score: 0.8633\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fc320282160>"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["print_hyperparameters_table(best_hyperparameters_cnn_v6_hyper_3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ef64f53a-0159-443c-9c6b-317a4abed4ac","id":"J625Ggw6DIcN"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["| Hyperparameter | Value |\n","| filters_1 | 64 |\n","| dropout_rate | 0.35 |\n","| kernel_height_width | 3 |\n","| learning_rate | 0.001 |\n","| n_conv2d | 2 |\n"]}]},{"cell_type":"code","source":["best_model_cnn_v6_hyper_3.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"09bd4372-21ef-473d-d481-4cd3c49e26bd","id":"HQVItej5DIcO"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"cnn_v6_hyper_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," batch_normalization (BatchN  multiple                 4         \n"," ormalization)                                                   \n","                                                                 \n"," conv2d (Conv2D)             multiple                  640       \n","                                                                 \n"," activation (Activation)     multiple                  0         \n","                                                                 \n"," max_pooling2d (MaxPooling2D  multiple                 0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           multiple                  36928     \n","                                                                 \n"," activation_1 (Activation)   multiple                  0         \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  multiple                 0         \n"," 2D)                                                             \n","                                                                 \n"," dropout (Dropout)           multiple                  0         \n","                                                                 \n"," flatten (Flatten)           multiple                  0         \n","                                                                 \n"," dense (Dense)               multiple                  230404    \n","                                                                 \n","=================================================================\n","Total params: 267,976\n","Trainable params: 267,974\n","Non-trainable params: 2\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["###CNN_V6_HYPER_4\n"],"metadata":{"id":"5ppDFWYdDIcP"}},{"cell_type":"markdown","source":["From analysing the previous model we understood that overfitting was present and a solution for this type of problems can be the use of Dropout layers. Dropout layers in this context can work as a regularization technique to prevent overfitting by randomly setting a fraction of the input units to 0 at each training iteration, which helps to prevent the model from relying too heavily on any single input unit.\n","\n","In sum, for each block of Conv2D, Activation and MaxPolling2D layers we added a Dropout layer.\n"],"metadata":{"id":"q52MwELKDIcQ"}},{"cell_type":"code","source":["class CNN_V6_HYPER_4(tf.keras.Model):\n","    def __init__(self, seed=0, filters_1=32, dropout_rate=0.25, kernel_height_width=3, n_conv2d=4):\n","        super().__init__()\n","        self.augmentation = augmentation\n","        self.batchnormalization = layers.BatchNormalization()\n","        self.conv_layers = []\n","        for i in range(n_conv2d):\n","            self.conv_layers.append(layers.Conv2D(filters=filters_1*input_shape[-1],\n","                                                  kernel_size=(kernel_height_width,kernel_height_width),\n","                                                  kernel_initializer=initializers.GlorotNormal(seed=seed),\n","                                                  kernel_regularizer=regularizers.l2(0.001)))\n","            self.conv_layers.append(layers.Activation(\"relu\"))\n","            self.conv_layers.append(layers.MaxPooling2D(pool_size=(2, 2)))\n","            self.conv_layers.append(layers.Dropout(dropout_rate))\n","        self.flatten = layers.Flatten()\n","        self.dense1 = layers.Dense(units=4, \n","                                   activation=\"softmax\", \n","                                   kernel_initializer=initializers.GlorotNormal(seed=seed),\n","                                   kernel_regularizer=regularizers.l2(0.001), \n","                                   activity_regularizer=regularizers.l1(0.001) \n","                                   ) \n","\n","    def call(self, inputs):\n","        x = self.augmentation(inputs)\n","        x = self.batchnormalization(x)\n","        for layer in self.conv_layers:\n","            x = layer(x)\n","        x = self.flatten(x)\n","        x = self.dense1(x)\n","        return x\n","\n","def build_model(hp):\n","    cnn_v6_hyper_4 = CNN_V6_HYPER_4(\n","        seed=seed,\n","        filters_1=hp.Int('filters_1', min_value=64, max_value=128, step=8),\n","        dropout_rate=hp.Float('dropout_rate', min_value=0.3, max_value=0.5, step=0.05),\n","        kernel_height_width=hp.Int('kernel_height_width', min_value=2, max_value=6, step=1),\n","        n_conv2d=hp.Int('n_conv2d', min_value=2, max_value=5, step=1)\n","    )\n","    cnn_v6_hyper_4.build(input_shape)\n","    cnn_v6_hyper_4.compile(\n","        optimizer=keras.optimizers.RMSprop(hp.Choice('learning_rate', values=[ 0.0005,0.001,0.005])),\n","        loss=\"categorical_crossentropy\",\n","        metrics=[metrics.CategoricalAccuracy(name='accuracy'),\n","        tfa.metrics.F1Score(num_classes=4, average='macro', name='F1-Score')])\n","\n","    return cnn_v6_hyper_4\n","\n","# Use Keras Tuner library to search for the best hyperparameters\n","tuner_cnn_v6_hyper_4= BayesianOptimization(\n","    build_model,\n","    objective=Objective('val_F1-Score', direction='max'),\n","    max_trials=5,\n","    overwrite=True,\n","    max_retries_per_trial=3\n","    )\n","\n","tuner_cnn_v6_hyper_4.search(ds_train, epochs=5, validation_data=ds_val,class_weight = class_weights)\n","\n","# Train the model with the best hyperparameters\n","best_model_cnn_v6_hyper_4 = tuner_cnn_v6_hyper_4.get_best_models(num_models=1)[0]\n","best_hyperparameters_cnn_v6_hyper_4 = tuner_cnn_v6_hyper_4.get_best_hyperparameters(num_trials=1)[0]\n","\n","best_model_cnn_v6_hyper_4.fit(ds_train, epochs=10, validation_data=ds_val,class_weight = class_weights)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"75e52640-add0-4db8-f105-e2a64330b5d6","id":"lskROW61DIcQ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 5 Complete [00h 00m 44s]\n","val_F1-Score: 0.7226176261901855\n","\n","Best val_F1-Score So Far: 0.7226176261901855\n","Total elapsed time: 00h 02m 45s\n","Epoch 1/10\n","36/36 [==============================] - 7s 154ms/step - loss: 1.5085 - accuracy: 0.7095 - F1-Score: 0.6961 - val_loss: 0.6590 - val_accuracy: 0.7822 - val_F1-Score: 0.7784\n","Epoch 2/10\n","36/36 [==============================] - 5s 136ms/step - loss: 1.3804 - accuracy: 0.7535 - F1-Score: 0.7409 - val_loss: 0.6418 - val_accuracy: 0.7735 - val_F1-Score: 0.7659\n","Epoch 3/10\n","36/36 [==============================] - 6s 160ms/step - loss: 1.2981 - accuracy: 0.7757 - F1-Score: 0.7695 - val_loss: 0.5648 - val_accuracy: 0.8188 - val_F1-Score: 0.8148\n","Epoch 4/10\n","36/36 [==============================] - 6s 137ms/step - loss: 1.1546 - accuracy: 0.8075 - F1-Score: 0.8045 - val_loss: 0.8067 - val_accuracy: 0.7143 - val_F1-Score: 0.6978\n","Epoch 5/10\n","36/36 [==============================] - 5s 134ms/step - loss: 1.0051 - accuracy: 0.8284 - F1-Score: 0.8230 - val_loss: 0.7927 - val_accuracy: 0.7073 - val_F1-Score: 0.6902\n","Epoch 6/10\n","36/36 [==============================] - 5s 136ms/step - loss: 1.0007 - accuracy: 0.8267 - F1-Score: 0.8227 - val_loss: 0.5579 - val_accuracy: 0.7927 - val_F1-Score: 0.7871\n","Epoch 7/10\n","36/36 [==============================] - 6s 148ms/step - loss: 0.9207 - accuracy: 0.8471 - F1-Score: 0.8440 - val_loss: 0.4841 - val_accuracy: 0.8571 - val_F1-Score: 0.8553\n","Epoch 8/10\n","36/36 [==============================] - 6s 135ms/step - loss: 0.8304 - accuracy: 0.8711 - F1-Score: 0.8700 - val_loss: 1.0462 - val_accuracy: 0.7003 - val_F1-Score: 0.6642\n","Epoch 9/10\n","36/36 [==============================] - 5s 135ms/step - loss: 0.8605 - accuracy: 0.8571 - F1-Score: 0.8530 - val_loss: 0.5636 - val_accuracy: 0.8084 - val_F1-Score: 0.8051\n","Epoch 10/10\n","36/36 [==============================] - 6s 142ms/step - loss: 0.8014 - accuracy: 0.8641 - F1-Score: 0.8615 - val_loss: 0.5196 - val_accuracy: 0.8328 - val_F1-Score: 0.8297\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fc2fe7ec9d0>"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["print_hyperparameters_table(best_hyperparameters_cnn_v6_hyper_4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e616f018-3173-4b3b-be99-f54e5afd1d0e","id":"qq54qeItDIcS"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["| Hyperparameter | Value |\n","| filters_1 | 104 |\n","| dropout_rate | 0.35 |\n","| kernel_height_width | 5 |\n","| learning_rate | 0.0005 |\n","| n_conv2d | 2 |\n"]}]},{"cell_type":"code","source":["best_model_cnn_v6_hyper_4.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"37e62536-7fe6-4ddf-8b29-47748d84bea1","id":"mLmzpzaoDIcT"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"cnn_v6_hyper_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," batch_normalization (BatchN  multiple                 4         \n"," ormalization)                                                   \n","                                                                 \n"," conv2d (Conv2D)             multiple                  2704      \n","                                                                 \n"," activation (Activation)     multiple                  0         \n","                                                                 \n"," max_pooling2d (MaxPooling2D  multiple                 0         \n"," )                                                               \n","                                                                 \n"," dropout (Dropout)           multiple                  0         \n","                                                                 \n"," conv2d_1 (Conv2D)           multiple                  270504    \n","                                                                 \n"," activation_1 (Activation)   multiple                  0         \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  multiple                 0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_1 (Dropout)         multiple                  0         \n","                                                                 \n"," flatten (Flatten)           multiple                  0         \n","                                                                 \n"," dense (Dense)               multiple                  349860    \n","                                                                 \n","=================================================================\n","Total params: 623,072\n","Trainable params: 623,070\n","Non-trainable params: 2\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["## **Hyperband**\n","\n","Until now, our group still believes that we can get better results and since the previous model didn't perform very well or settle our overfitting problem we thought about using other hyperparameter tuning technique called Hyperband.\n","\n","Hyperband works as a combination of random search and adaptive resource allocation to efficiently search the hyperparameter space and find optimal hyperparameter configurations for a machine learning model. It allocates resources (nº of epochs) dynamically to different hyperparameter configurations based on their performance. It starts by training multiple models with random hyperparameter configurations for a small number of epochs, and then selects a fraction of the top-performing models (based on their validation performance) to continue training with more epochs. This process is repeated in successive rounds, with fewer models and more epochs allocated to the top-performing configurations at each round. This allows Hyperband to allocate more resources to promising hyperparameter configurations and converge towards the optimal hyperparameter values faster.\n","\n"],"metadata":{"id":"9nxMfoXiDIcU"}},{"cell_type":"markdown","source":["###CNN_V6_HYPER_5\n"],"metadata":{"id":"QoAJamUYDIcU"}},{"cell_type":"code","source":["class CNN_V6_HYPER_5(tf.keras.Model):\n","    def __init__(self, seed=0, filters_1=32, dropout_rate=0.25, kernel_height_width=3, n_conv2d=5):\n","        super().__init__()\n","        self.augmentation = augmentation\n","        self.batchnormalization = layers.BatchNormalization()\n","        self.conv_layers = []\n","        for i in range(n_conv2d):\n","            self.conv_layers.append(layers.Conv2D(filters=filters_1*input_shape[-1],\n","                                                  kernel_size=(kernel_height_width,kernel_height_width),\n","                                                  kernel_initializer=initializers.GlorotNormal(seed=seed),\n","                                                  kernel_regularizer=regularizers.l2(0.001)))\n","            self.conv_layers.append(layers.Activation(\"relu\"))\n","            self.conv_layers.append(layers.MaxPooling2D(pool_size=(2, 2)))\n","            self.conv_layers.append(layers.Dropout(dropout_rate))\n","        self.flatten = layers.Flatten()\n","        self.dense1 = layers.Dense(units=4, \n","                                   activation=\"softmax\", \n","                                   kernel_initializer=initializers.GlorotNormal(seed=seed),\n","                                   kernel_regularizer=regularizers.l2(0.001), \n","                                   activity_regularizer=regularizers.l1(0.001) \n","                                   ) \n","\n","    def call(self, inputs):\n","        x = self.augmentation(inputs)\n","        x = self.batchnormalization(x)\n","        for layer in self.conv_layers:\n","            x = layer(x)\n","        x = self.flatten(x)\n","        x = self.dense1(x)\n","        return x\n","\n","def build_model(hp):\n","    cnn_v6_hyper_5 = CNN_V6_HYPER_5(\n","        seed=seed,\n","        filters_1=hp.Int('filters_1', min_value=64, max_value=128, step=8),\n","        dropout_rate=hp.Float('dropout_rate', min_value=0.3, max_value=0.5, step=0.05),\n","        kernel_height_width=hp.Int('kernel_height_width', min_value=2, max_value=6, step=1),\n","        n_conv2d=hp.Int('n_conv2d', min_value=2, max_value=5, step=1)\n","    )\n","    cnn_v6_hyper_5.build(input_shape)\n","    cnn_v6_hyper_5.compile(\n","        optimizer=keras.optimizers.RMSprop(hp.Choice('learning_rate', values=[ 0.0005,0.001,0.005])),\n","        loss=\"categorical_crossentropy\",\n","        metrics=[metrics.CategoricalAccuracy(name='accuracy'),\n","        tfa.metrics.F1Score(num_classes=4, average='macro', name='F1-Score')])\n","\n","    return cnn_v6_hyper_5\n","# Use Keras Tuner library to search for the best hyperparameters\n","tuner_cnn_v6_hyper_5 = Hyperband(\n","    build_model,\n","    objective=Objective('val_F1-Score', direction='max'),\n","    max_epochs=10,\n","    factor=3,\n","    overwrite=True,\n","    max_retries_per_trial=3\n",")\n","\n","tuner_cnn_v6_hyper_5.search(ds_train, epochs=5, validation_data=ds_val,class_weight = class_weights)\n","\n","# Train the model with the best hyperparameters\n","best_model_cnn_v6_hyper_5 = tuner_cnn_v6_hyper_5.get_best_models(num_models=1)[0]\n","best_hyperparameters_cnn_v6_hyper_5 = tuner_cnn_v6_hyper_5.get_best_hyperparameters(num_trials=1)[0]\n","\n","best_model_cnn_v6_hyper_5.fit(ds_train, epochs=10, validation_data=ds_val,class_weight = class_weights)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"60bd819e-f4be-4318-d64f-f99a7cb5d169","executionInfo":{"status":"ok","timestamp":1680977109380,"user_tz":-60,"elapsed":896387,"user":{"displayName":"InfoSS","userId":"03001223037444999152"}},"id":"ZivCt4jRDIcW"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 28 Complete [00h 01m 12s]\n","val_F1-Score: 0.7593338489532471\n","\n","Best val_F1-Score So Far: 0.8430914282798767\n","Total elapsed time: 00h 13m 27s\n","Epoch 1/10\n","36/36 [==============================] - 8s 160ms/step - loss: 1.2831 - accuracy: 0.7940 - F1-Score: 0.7888 - val_loss: 0.8532 - val_accuracy: 0.7282 - val_F1-Score: 0.7150\n","Epoch 2/10\n","36/36 [==============================] - 6s 159ms/step - loss: 1.2614 - accuracy: 0.8092 - F1-Score: 0.8096 - val_loss: 0.7360 - val_accuracy: 0.7875 - val_F1-Score: 0.7818\n","Epoch 3/10\n","36/36 [==============================] - 7s 180ms/step - loss: 1.0744 - accuracy: 0.8341 - F1-Score: 0.8286 - val_loss: 0.5815 - val_accuracy: 0.8606 - val_F1-Score: 0.8584\n","Epoch 4/10\n","36/36 [==============================] - 6s 152ms/step - loss: 1.0379 - accuracy: 0.8528 - F1-Score: 0.8519 - val_loss: 0.5235 - val_accuracy: 0.8728 - val_F1-Score: 0.8732\n","Epoch 5/10\n","36/36 [==============================] - 6s 153ms/step - loss: 0.9253 - accuracy: 0.8689 - F1-Score: 0.8674 - val_loss: 0.5304 - val_accuracy: 0.8955 - val_F1-Score: 0.8927\n","Epoch 6/10\n","36/36 [==============================] - 7s 182ms/step - loss: 0.9413 - accuracy: 0.8672 - F1-Score: 0.8648 - val_loss: 0.5250 - val_accuracy: 0.8833 - val_F1-Score: 0.8832\n","Epoch 7/10\n","36/36 [==============================] - 6s 151ms/step - loss: 0.8598 - accuracy: 0.8850 - F1-Score: 0.8833 - val_loss: 1.0788 - val_accuracy: 0.7334 - val_F1-Score: 0.7151\n","Epoch 8/10\n","36/36 [==============================] - 6s 156ms/step - loss: 0.8243 - accuracy: 0.8950 - F1-Score: 0.8916 - val_loss: 0.5803 - val_accuracy: 0.8728 - val_F1-Score: 0.8735\n","Epoch 9/10\n","36/36 [==============================] - 6s 165ms/step - loss: 0.7723 - accuracy: 0.8985 - F1-Score: 0.8962 - val_loss: 0.4446 - val_accuracy: 0.9303 - val_F1-Score: 0.9253\n","Epoch 10/10\n","36/36 [==============================] - 6s 151ms/step - loss: 0.7781 - accuracy: 0.9059 - F1-Score: 0.9037 - val_loss: 0.5077 - val_accuracy: 0.9111 - val_F1-Score: 0.9100\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f327132c670>"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["print_hyperparameters_table(best_hyperparameters_cnn_v6_hyper_5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b5b7a282-f5a9-4183-e644-472fa85100e2","executionInfo":{"status":"ok","timestamp":1680977120784,"user_tz":-60,"elapsed":323,"user":{"displayName":"InfoSS","userId":"03001223037444999152"}},"id":"riuOnn-4DIcX"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["| Hyperparameter | Value |\n","| filters_1 | 112 |\n","| dropout_rate | 0.3 |\n","| kernel_height_width | 4 |\n","| learning_rate | 0.001 |\n","| n_conv2d | 4 |\n"]}]},{"cell_type":"code","source":["best_model_cnn_v6_hyper_5.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fe0b0306-7f27-4147-a9c9-51451cd7b850","executionInfo":{"status":"ok","timestamp":1680977123608,"user_tz":-60,"elapsed":381,"user":{"displayName":"InfoSS","userId":"03001223037444999152"}},"id":"gEkkDXPJDIcY"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"cnn_v6_hyper_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," batch_normalization (BatchN  multiple                 4         \n"," ormalization)                                                   \n","                                                                 \n"," conv2d (Conv2D)             multiple                  1904      \n","                                                                 \n"," activation (Activation)     multiple                  0         \n","                                                                 \n"," max_pooling2d (MaxPooling2D  multiple                 0         \n"," )                                                               \n","                                                                 \n"," dropout (Dropout)           multiple                  0         \n","                                                                 \n"," conv2d_1 (Conv2D)           multiple                  200816    \n","                                                                 \n"," activation_1 (Activation)   multiple                  0         \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  multiple                 0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_1 (Dropout)         multiple                  0         \n","                                                                 \n"," conv2d_2 (Conv2D)           multiple                  200816    \n","                                                                 \n"," activation_2 (Activation)   multiple                  0         \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  multiple                 0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_2 (Dropout)         multiple                  0         \n","                                                                 \n"," conv2d_3 (Conv2D)           multiple                  200816    \n","                                                                 \n"," activation_3 (Activation)   multiple                  0         \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  multiple                 0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_3 (Dropout)         multiple                  0         \n","                                                                 \n"," flatten (Flatten)           multiple                  0         \n","                                                                 \n"," dense (Dense)               multiple                  11204     \n","                                                                 \n","=================================================================\n","Total params: 615,560\n","Trainable params: 615,558\n","Non-trainable params: 2\n","_________________________________________________________________\n"]}]}]}