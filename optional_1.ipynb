{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["ErjcEAeE_op3"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# **Ensemble Learning**"],"metadata":{"id":"eCaiy-XXsxr_"}},{"cell_type":"markdown","source":["### **Student Identification**"],"metadata":{"id":"-2wRS0QxWeuY"}},{"cell_type":"markdown","source":["Student Name       | Student Email\n","-------------------|------------------\n","Daniel Branco      | r20191230@novaims.unl.pt\n","Filipe Dias        | r20181050@novaims.unl.pt\n","Gonçalo Lourenço   | r20191097@novaims.unl.pt\n","Inês Santos        | r20191184@novaims.unl.pt\n","Manuel Marreiros   | r20191223@novaims.unl.pt"],"metadata":{"id":"m3SxcKjUCefA"}},{"cell_type":"markdown","source":["### **Data Source**\n","\n","Brain Tumor Classification (MRI) Dataset: https://www.kaggle.com/datasets/sartajbhuvaji/brain-tumor-classification-mri\n","\n","Drive with data: https://drive.google.com/file/d/1P3hcUss5Kqb28_WQUcTsuTW2VjNTX4pd/view?usp=share_link"],"metadata":{"id":"zDfu7s5EtOYW"}},{"cell_type":"markdown","source":["### **Notebook Summary**\n","\n","\n","\n"],"metadata":{"id":"-OR0ihcitTf7"}},{"cell_type":"markdown","source":["In this notebook we applied a technique called **ensemble learning**. The ensemble of classifiers seeks better predictive performance by combining the predictions from multiple models. In fact, it is proven that an ensemble of classifiers is typically more accurate than a single classifier, which makes this a very important tool in classification tasks.\n","\n","Here, we will try to merge some of our models (namely convolutional neural networks 4, 5 and 6) and see how the performance compares to the individual models."],"metadata":{"id":"_WbxnE0z4NEi"}},{"cell_type":"markdown","source":["### **References**\n","\n","1. [Ensemble deep learning: A review\n","](https://arxiv.org/pdf/2104.02395.pdf)"],"metadata":{"id":"MDkeW9SOUotp"}},{"cell_type":"markdown","source":["### **Imports**"],"metadata":{"id":"BrN6EI5vnQNX"}},{"cell_type":"code","source":["pip install keras-tuner tensorflow-addons --quiet"],"metadata":{"id":"SOWF-hCSU74z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import time\n","import math\n","import random \n","import zipfile\n","import shutil\n","\n","import numpy as np\n","import pandas as pd\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","from matplotlib.colors import ListedColormap\n","\n","import tensorflow as tf\n","from tensorflow.keras import datasets\n","from tensorflow.keras.preprocessing import image_dataset_from_directory\n","from tensorflow.keras import Sequential, Model, layers, initializers, regularizers, optimizers, metrics \n","from tensorflow.keras.initializers import GlorotNormal\n","import tensorflow_addons as tfa\n","\n","import keras\n","from keras_tuner import Objective\n","import keras_tuner as kt\n","from kerastuner.tuners import RandomSearch\n","from kerastuner.engine.hyperparameters import HyperParameters\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score"],"metadata":{"id":"kEMwDnEcWuTn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Things needed from previous notebooks**"],"metadata":{"id":"ErjcEAeE_op3"}},{"cell_type":"code","source":["#EXPLORATION\n","\n","# Set the machine\n","gdrive = True\n","# Set the connection string\n","path = \"/content/drive/MyDrive/Deep Learning/Projeto/\"\n","main_folder, training_folder, testing_folder = \"brain_tumor_data/\", \"Training/\", \"Testing/\"\n","# If using Google Drive\n","if gdrive:\n","    # Setup drive\n","    from google.colab import drive\n","    drive.mount('/content/drive')        \n","    # Transfer zip dataset to the current virtual machine\n","    t0 = time.time()\n","    shutil.copyfile(path + 'brain_tumor_data.zip', 'brain_tumor_data.zip')\n","    # Extract files\n","    zip_ = zipfile.ZipFile('brain_tumor_data.zip')\n","    zip_.extractall()\n","    zip_.close()\n","    print(\"File transfer completed in %0.3f seconds\" % (time.time() - t0))\n","    path = \"\"\n","\n","classes = [\"no_tumor\", \"glioma_tumor\", \"meningioma_tumor\", \"pituitary_tumor\"]\n","\n","# Create empty lists to store the number of instances and class names\n","n_train = []\n","class_names = []\n","\n","# Loop through each class in the dataset\n","for c in classes:\n","    # Get the number of instances in the training set for the current class\n","    n_train_c = len(os.listdir(path + main_folder + training_folder + f\"/{c}\"))\n","    # Append the number of instances and class name to their respective lists\n","    n_train.append(n_train_c)\n","    class_names.append(c)\n","\n","image_size=(128, 128)\n","crop_to_aspect_ratio=True\n","color_mode='grayscale'\n","batch_size=64\n","label_mode=\"categorical\"\n","validation_split=0.2\n","shuffle=True\n","seed=0\n","\n","ds_train, ds_val = image_dataset_from_directory(path + main_folder + training_folder, \n","                                                image_size=image_size,\n","                                                crop_to_aspect_ratio=crop_to_aspect_ratio,\n","                                                color_mode=color_mode,\n","                                                batch_size=batch_size,\n","                                                label_mode=label_mode,\n","                                                subset='both',\n","                                                validation_split=validation_split, \n","                                                shuffle=shuffle,\n","                                                seed=seed)\n","\n","iter_train = iter(ds_train)\n","batch_x_train, batch_y_train = iter_train.next()\n","\n","n_classes = len(classes)\n","total_samples = np.sum(n_train)\n","\n","#PREPROCESSING\n","\n","class_weights = {}\n","for i in range(n_classes):\n","    w = total_samples / (2.0 * n_train[i])\n","    class_weights[i] = w\n","\n","print('Class counts:', n_train)\n","print('Class weights:', class_weights)\n","\n","input_shape = tuple(batch_x_train.shape)\n","rescaling = layers.Rescaling(1./255)\n","batchnormalization = layers.BatchNormalization()\n","\n","rotation_layer = layers.RandomRotation(factor=0.05)\n","zoom_layer = layers.RandomZoom(height_factor=0.05, width_factor=0.05)\n","contrast_layer = layers.RandomContrast(factor=0.10)\n","brightness_layer = layers.RandomBrightness(factor=0.05)\n","noise_layer = layers.GaussianNoise(0.05)\n","flip_layer = layers.RandomFlip(mode='horizontal')\n","crop_layer = layers.RandomCrop(height=300, width=300)\n","translation_layer = layers.RandomTranslation(height_factor=0.1, width_factor=0.1)\n","\n","def augmentation(inputs):\n","    x = rotation_layer(inputs)\n","    x = zoom_layer(x)\n","    x = contrast_layer(x)\n","    x = brightness_layer(x)\n","    x = noise_layer(x)\n","    return x\n","\n","#MODEL HANDCRAFTED\n","class CNN4(tf.keras.Model):\n","    def __init__(self, seed=0):\n","        super().__init__()\n","        self.augmentation = augmentation\n","        self.batchnormalization = layers.BatchNormalization()\n","        self.conv1 = layers.Conv2D(filters=32*input_shape[-1], kernel_size=(3, 3), kernel_initializer=initializers.GlorotNormal(seed=seed))\n","        self.relu = layers.Activation(\"relu\")\n","        self.maxpool1 = layers.MaxPooling2D(pool_size=(2, 2))          \n","        self.conv2 = layers.Conv2D(filters=64*input_shape[-1], kernel_size=(3, 3), kernel_initializer=initializers.GlorotNormal(seed=seed))\n","        self.maxpool2 = layers.MaxPooling2D(pool_size=(2, 2))      \n","        self.flatten = layers.Flatten()\n","        self.dense1 = layers.Dense(units=4, activation=\"softmax\", kernel_initializer=initializers.GlorotNormal(seed=seed)) \n","        \n","    def call(self, inputs):\n","        x = self.augmentation(inputs)\n","        x = self.batchnormalization(x)\n","        x = self.conv1(x)\n","        x = self.relu(x)\n","        x = self.maxpool1(x)\n","        x = self.conv2(x)\n","        x = self.relu(x)\n","        x = self.maxpool2(x)\n","        x = self.flatten(x)\n","        x = self.dense1(x)\n","        return x\n","\n","class CNN5(tf.keras.Model):\n","    def __init__(self, seed=0):\n","        super().__init__()\n","        self.augmentation = augmentation\n","        self.batchnormalization = layers.BatchNormalization()\n","        self.conv1 = layers.Conv2D(filters=32*input_shape[-1], kernel_size=(3, 3), kernel_initializer=initializers.GlorotNormal(seed=seed))\n","        self.relu = layers.Activation(\"relu\")\n","        self.maxpool = layers.MaxPooling2D(pool_size=(2, 2))          \n","        self.conv2 = layers.Conv2D(filters=64*input_shape[-1], kernel_size=(3, 3), kernel_initializer=initializers.GlorotNormal(seed=seed))\n","        self.dropout = layers.Dropout(0.3) #rate at which input units are set to 0\n","        self.flatten = layers.Flatten()\n","        self.dense1 = layers.Dense(units=4, activation=\"softmax\", kernel_initializer=initializers.GlorotNormal(seed=seed)) \n","        \n","    def call(self, inputs):\n","        x = self.augmentation(inputs)\n","        x = self.batchnormalization(x)\n","        x = self.conv1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","        x = self.conv2(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","        x = self.dropout(x)\n","        x = self.flatten(x)\n","        x = self.dense1(x)\n","        return x\n","\n","class CNN6(tf.keras.Model):\n","    def __init__(self, seed=0):\n","        super().__init__()\n","        self.augmentation = augmentation\n","        self.batchnormalization = layers.BatchNormalization()\n","        self.conv1 = layers.Conv2D(\n","            filters=32*input_shape[-1], \n","            kernel_size=(3, 3), \n","            kernel_initializer=initializers.GlorotNormal(seed=seed),\n","            kernel_regularizer=regularizers.l2(0.001), # Adding kernel_regularizer\n","        )\n","        self.relu = layers.Activation(\"relu\")\n","        self.maxpool = layers.MaxPooling2D(pool_size=(2, 2))          \n","        self.conv2 = layers.Conv2D(\n","            filters=64*input_shape[-1], \n","            kernel_size=(3, 3), \n","            kernel_initializer=initializers.GlorotNormal(seed=seed),\n","            kernel_regularizer=regularizers.l2(0.001), # Adding kernel_regularizer\n","        )\n","        self.dropout = layers.Dropout(0.3) #rate at which input units are set to 0\n","        self.flatten = layers.Flatten()\n","        self.dense1 = layers.Dense(\n","            units=4, \n","            activation=\"softmax\", \n","            kernel_initializer=initializers.GlorotNormal(seed=seed),\n","            kernel_regularizer=regularizers.l2(0.001), # Adding kernel_regularizer\n","            activity_regularizer=regularizers.l1(0.001) # Adding activity_regularizer\n","        ) \n","        \n","    def call(self, inputs):\n","        x = self.augmentation(inputs)\n","        x = self.batchnormalization(x)\n","        x = self.conv1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","        x = self.conv2(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","        x = self.dropout(x)\n","        x = self.flatten(x)\n","        x = self.dense1(x)\n","        return x\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tNoBv_Yd_4hG","executionInfo":{"status":"ok","timestamp":1680780398481,"user_tz":-60,"elapsed":4317,"user":{"displayName":"Manuel Marreiros","userId":"12533604716124934097"}},"outputId":"75c64117-173e-41b4-8ebf-b5feebb3f576"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","File transfer completed in 1.896 seconds\n","Found 2870 files belonging to 4 classes.\n","Using 2296 files for training.\n","Using 574 files for validation.\n"]}]},{"cell_type":"markdown","source":["## **Ensemble of Classifiers**"],"metadata":{"id":"lncJCrnQXN9V"}},{"cell_type":"markdown","source":["Let's start by creating, compiling and training three of our best models."],"metadata":{"id":"ECq243NkWgDO"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"rg98d5Me3O6l"},"outputs":[],"source":["cnn4 = CNN4(seed=seed)\n","cnn5 = CNN4(seed=seed)\n","cnn6 = CNN4(seed=seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vrTAWS4R32rW"},"outputs":[],"source":["cnn4.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[metrics.CategoricalAccuracy(name='accuracy'),\n","        tfa.metrics.F1Score(num_classes=4, average='macro', name='F1-Score')])\n","cnn4.fit(ds_train, epochs=epochs, validation_data=ds_val, class_weight = class_weights)\n","\n","cnn5.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[metrics.CategoricalAccuracy(name='accuracy'),\n","        tfa.metrics.F1Score(num_classes=4, average='macro', name='F1-Score')])\n","cnn5.fit(ds_train, epochs=epochs, validation_data=ds_val, class_weight = class_weights)\n","\n","cnn6.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[metrics.CategoricalAccuracy(name='accuracy'),\n","        tfa.metrics.F1Score(num_classes=4, average='macro', name='F1-Score')])\n","cnn6.fit(ds_train, epochs=epochs, validation_data=ds_val, class_weight = class_weights)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UL-pnxXh34Co","executionInfo":{"status":"ok","timestamp":1680897572373,"user_tz":-60,"elapsed":1371,"user":{"displayName":"InfoSS","userId":"03001223037444999152"}},"outputId":"ed3448e0-d230-4daf-e8bf-a4cf000dc574"},"outputs":[{"output_type":"stream","name":"stdout","text":["7/7 [==============================] - 1s 23ms/step\n","7/7 [==============================] - 0s 7ms/step\n","7/7 [==============================] - 0s 10ms/step\n"]}],"source":["from numpy import argmax\n","\n","# Predict the test set using each model\n","y_pred_1 = cnn4.predict(ds_test)\n","y_pred_2 = cnn5.predict(ds_test)\n","y_pred_3 = cnn6.predict(ds_test)\n","\n","# Combine the predictions\n","y_pred_ensemble = argmax(y_pred_1 + y_pred_2 + y_pred_3, axis=1)\n"]},{"cell_type":"markdown","source":["Firstly, the test set ds_test is passed through each of the three CNN models, and the predicted classes are obtained for each input image. The predictions are stored in y_pred_1, y_pred_2, and y_pred_3, respectively.\n","\n","Then, the ensemble prediction is performed by combining the individual predictions from the three models, which returns the most frequent value.\n","\n","Finally, the resulting ensemble predictions are stored in y_pred_ensemble, which contains the predicted class labels for each input image in the test set, based on the combined output of the three CNN models."],"metadata":{"id":"Rq9wE_PFVHft"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t7jqxbfh0iEc","executionInfo":{"status":"ok","timestamp":1680897579973,"user_tz":-60,"elapsed":550,"user":{"displayName":"InfoSS","userId":"03001223037444999152"}},"outputId":"67bc44d3-188a-4e9f-e83c-4567b00422f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1 2 2 2 2 2 1 2 2 1 1 2 1 2 2 3 2 1 2 1 2 2 2 2 2 1 2 2 2 0 1 2 2 2 1 1 2\n"," 2 3 2 2 1 2 1 2 1 3 2 3 2 0 2 2 2 2 2 0 1 2 1 1 2 0 2 2 1 2 2 2 1 3 2 2 2\n"," 2 2 2 1 2 2 2 2 0 2 2 2 2 2 2 2 2 2 1 2 1 3 2 2 2 2 1 1 2 2 2 2 3 1 1 2 2\n"," 2 2 1 2 2 2 3 0 1 2 2 2 0 1 2 2 2 3 2 2 2 2 2 2 1 1 2 2 2 3 2 2 2 2 1 2 2\n"," 2 2 2 3 1 0 2 1 2 1 2 2 2 1 2 2 3 2 2 2 2 2 2 2 2 3 3 2 2 2 1 1 2 2 2 1 1\n"," 2 1 2 2 2 3 2 2 1 2 2 2 3 2 2 1 3 2 3 1 2 1 1 2 0 2 2 2 2 2 3 1 2 2 1 3 2\n"," 1 2 2 3 3 1 1 2 2 2 3 1 2 3 3 3 1 1 3 2 0 2 2 2 3 2 2 2 3 0 3 2 1 1 2 2 2\n"," 1 1 2 3 2 2 3 3 1 2 1 2 2 2 2 2 2 0 1 1 2 1 2 3 1 2 2 2 2 1 3 1 2 1 1 1 1\n"," 2 3 1 3 2 2 2 3 2 2 1 2 1 2 2 1 2 3 2 2 1 3 3 2 3 1 0 2 1 1 1 2 1 1 2 2 2\n"," 2 1 3 2 0 2 3 1 2 2 1 2 2 1 3 2 3 2 2 3 2 3 2 1 1 1 2 1 3 2 2 2 1 2 3 2 2\n"," 2 2 3 1 2 1 3 1 2 3 3 1 2 1 0 2 0 2 2 1 2 3 2 2]\n"]}],"source":["print(y_pred_ensemble)"]}]}